{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import math\n",
    "\n",
    "from IPython import display\n",
    "from matplotlib import cm\n",
    "from matplotlib import gridspec\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.data import Dataset\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = '{:.1f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the data\n",
    "housing_df = pd.read_csv(\"train_LR.csv\", sep=\",\")\n",
    "housing_df = shuffle(housing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Processing the data\n",
    "processed_features = housing_df[[\"GrLivArea\"]]\n",
    "\n",
    "output_targets = pd.DataFrame(housing_df[\"SalePrice\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Splitting the data into training, validation, and test sets\n",
    "training_examples = processed_features[0:1060]\n",
    "training_targets = output_targets[0:1060]\n",
    "\n",
    "val_examples = processed_features[1060:1260]\n",
    "val_targets = output_targets[1060:1260]\n",
    "\n",
    "test_examples = processed_features[1260:1460]\n",
    "test_targets = output_targets[1260:1460]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure a numeric feature column for total_rooms.\n",
    "my_feature_columns = [tf.feature_column.numeric_column(\"GrLivArea\")]\n",
    "\n",
    "# Define the preferred optimizer: in this case lets use gradient descent\n",
    "my_optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n",
    "\n",
    "# here is the difference between previous linear regression class\n",
    "# Configure the linear regression model with our feature columns, hidden layers, and optimizer.\n",
    "\n",
    "# https://www.kaggle.com/usersumit/tensorflow-dnnregressor\n",
    "model = tf.estimator.DNNRegressor(feature_columns=my_feature_columns,hidden_units=[12,12],optimizer=my_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the input function required for training\n",
    "def my_input_fn(features, targets, batch_size=1, shuffle=True, num_epochs=None):\n",
    "\n",
    "# Convert pandas data into a dict of np arrays.\n",
    "# dictionary comprehension\n",
    "# https://www.datacamp.com/community/tutorials/python-dictionary-comprehension\n",
    "    features = {key:np.array(value) for key,value in dict(features).items()}                                           \n",
    " \n",
    "    # Construct a dataset, and configure batching/repeating.\n",
    "    ds = Dataset.from_tensor_slices((features,targets)) # warning: 2GB limit\n",
    "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
    "    \n",
    "    # Shuffle the data, if specified.\n",
    "    if shuffle:\n",
    "      ds = ds.shuffle(buffer_size=10000)\n",
    "      \n",
    "    # Return the next batch of data.\n",
    "    features, labels = ds.make_one_shot_iterator().get_next()\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model from the existing data\n",
    "training = model.train(input_fn = lambda:my_input_fn(training_examples,training_targets[\"SalePrice\"],batch_size=32),steps=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (on training data): 56348.057\n",
      "Root Mean Squared Error (on validation data): 53484.164\n",
      "Root Mean Squared Error (on test data): 59448.892\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model with RMSE\n",
    "train_predictions = model.predict(input_fn=lambda: my_input_fn(training_examples, training_targets, num_epochs=1, shuffle=False))\n",
    "val_predictions = model.predict(input_fn=lambda: my_input_fn(val_examples, val_targets, num_epochs=1, shuffle=False))\n",
    "test_predictions = model.predict(input_fn=lambda: my_input_fn(test_examples, test_targets, num_epochs=1, shuffle=False))\n",
    "\n",
    "# Format predictions as a NumPy array, so we can calculate error metrics.\n",
    "train_predictions = np.array([item['predictions'][0] for item in train_predictions])\n",
    "val_predictions = np.array([item['predictions'][0] for item in val_predictions])\n",
    "test_predictions = np.array([item['predictions'][0] for item in test_predictions])\n",
    "\n",
    "# Print Mean Squared Error and Root Mean Squared Error.\n",
    "mean_squared_error = metrics.mean_squared_error(train_predictions, training_targets)\n",
    "root_mean_squared_error = math.sqrt(mean_squared_error)\n",
    "print(\"Root Mean Squared Error (on training data): %0.3f\" % root_mean_squared_error)\n",
    "mean_squared_error = metrics.mean_squared_error(val_predictions, val_targets)\n",
    "root_mean_squared_error = math.sqrt(mean_squared_error)\n",
    "print(\"Root Mean Squared Error (on validation data): %0.3f\" % root_mean_squared_error)\n",
    "mean_squared_error = metrics.mean_squared_error(test_predictions, test_targets)\n",
    "root_mean_squared_error = math.sqrt(mean_squared_error)\n",
    "print(\"Root Mean Squared Error (on test data): %0.3f\" % root_mean_squared_error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
